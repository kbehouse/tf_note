{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=Tensor(\"Sum:0\", shape=(), dtype=int32)\n",
      "a = 6\n",
      "b = [3 3]\n",
      "c = [2 4]\n"
     ]
    }
   ],
   "source": [
    "#-----Test for reduce_sum------#\n",
    "import tensorflow as tf\n",
    "# 'x' is [[1, 1, 1]\n",
    "#         [1, 1, 1]]\n",
    "# x = tf.constant([[1, 1, 1],\n",
    "#                        [1, 1, 1]])\n",
    "\n",
    "x = tf.constant([[1,1],\n",
    "                 [2,2]])\n",
    "a = tf.reduce_sum(x) \n",
    "b = tf.reduce_sum(x, 0) \n",
    "c = tf.reduce_sum(x, 1) \n",
    "\n",
    "print('a='+str(a))\n",
    "with tf.Session() as sess:\n",
    "    print 'a = ' + str(sess.run(a))\n",
    "    print 'b = ' + str(sess.run(b))\n",
    "    print 'c = ' + str(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=Tensor(\"Sum:0\", shape=(2, 3), dtype=int32)\n",
      "a = [[4 6 5]\n",
      " [6 6 6]]\n",
      "b = [[6 8 7]\n",
      " [4 4 4]]\n"
     ]
    }
   ],
   "source": [
    "#-----Test for reduce_sum------#\n",
    "A = [ [\n",
    "        [4,6, 5 ], \n",
    "        [2,2, 2]\n",
    "      ],\n",
    "      [\n",
    "        [0,0, 0 ],\n",
    "        [4,4, 4 ] \n",
    "      ]\n",
    "]\n",
    "\n",
    "a = tf.reduce_sum(A, 0) \n",
    "b = tf.reduce_sum(A, 1) \n",
    "\n",
    "print('a='+str(a))\n",
    "with tf.Session() as sess:\n",
    "    print 'a = ' + str(sess.run(a))\n",
    "    print 'b = ' + str(sess.run(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-55087ba30ccf>:18: arg_min (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmin` instead\n",
      "dis = [ 12.   3.   3.   9.  12.]\n",
      "pred = 1\n"
     ]
    }
   ],
   "source": [
    "#-----Test for nearest_neighbor------#\n",
    "A = [ [4,6, 5 ], [2,2, 2],[0,0, 0 ],[4,4, 4 ],[5, 5, 5 ]]\n",
    "A_Label = [1, 2, 3, 4, 5]\n",
    "B = [ [1,1, 1 ]]\n",
    "\n",
    "\n",
    "\n",
    "# tf Graph Input\n",
    "xtr = tf.placeholder(\"float\", [None, 3])\n",
    "xte = tf.placeholder(\"float\", [3])\n",
    "\n",
    "# Nearest Neighbor calculation using L1 Distance\n",
    "# Calculate L1 Distance\n",
    "distance = tf.reduce_sum(tf.abs(tf.add(xtr, tf.negative(xte))), reduction_indices=1)\n",
    "#dis = [  0.   3.   6.   9.  12.]\n",
    "\n",
    "# Prediction: Get min distance index (Nearest neighbor)\n",
    "pred = tf.arg_min(distance, 0)\n",
    "\n",
    "accuracy = 0.\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    dis = sess.run(distance, feed_dict={xtr: A, xte: B[0]})\n",
    "    print('dis = '+ str(dis))\n",
    "    \n",
    "    pred = sess.run(pred, feed_dict={xtr: A, xte: B[0]})\n",
    "    print('pred = '+ str(pred))\n",
    "#     # loop over test data\n",
    "#     for i in range(len(B)):\n",
    "#         # Get nearest neighbor\n",
    "#         nn_index = sess.run(pred, feed_dict={xtr: A, xte: B[i, :]})\n",
    "#         # Get nearest neighbor class label and compare it to its true label\n",
    "#         print \"Test\", i, \"Prediction:\", np.argmax(Ytr[nn_index]), \\\n",
    "#             \"True Class:\", np.argmax(Yte[i])\n",
    "#         # Calculate accuracy\n",
    "#         if np.argmax(Ytr[nn_index]) == np.argmax(Yte[i]):\n",
    "#             accuracy += 1./len(Xte)\n",
    "#     print \"Done!\"\n",
    "#     print \"Accuracy:\", accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------Test Softmax-------#\n",
    "\n",
    "\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    dis = sess.run(distance, feed_dict={xtr: A, xte: B[0]})\n",
    "    print('dis = '+ str(dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999989359\n"
     ]
    }
   ],
   "source": [
    "#-----Softmax Test------#\n",
    "sx = tf.nn.softmax([-6.0,0.0,3.0,6.0]) # Softmax\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    ary =  sess.run(sx)\n",
    "    \n",
    "print(sum(ary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.   3.   3.]\n",
      " [ 10.  20.  30.]]\n",
      "[[  3.   6.   9.]\n",
      " [ 20.  40.  60.]]\n",
      "[[  0.           2.07944155   3.29583693]\n",
      " [  6.93147182  13.86294365  20.79441452]]\n"
     ]
    }
   ],
   "source": [
    "#-----  A * B  is not A.matmul(B)------#\n",
    "A = [ [1.0,2.0, 3.0], \n",
    "      [2.0,2.0, 2.0]] \n",
    "\n",
    "B = [ [3,3, 3 ],\n",
    "      [10, 20, 30 ]]\n",
    "\n",
    "y = tf.placeholder(tf.float32, [None, 3]) \n",
    "\n",
    "\n",
    "   \n",
    "with tf.Session() as sess:\n",
    "    print sess.run( y , feed_dict={y: B} )\n",
    "    print sess.run( y* (A), feed_dict={y: B})\n",
    "    print sess.run( y* tf.log(A), feed_dict={y: B})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.argmax()\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "B = [ [ 3,  7,  2 ,99,200,3],\n",
    "      [10, 20, 30 ,1 ,  3,2 ]]\n",
    "\n",
    "m = tf.argmax(B, 1)\n",
    "\n",
    "print tf.Session().run(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.unstack()\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u = [array([4, 6, 5], dtype=int32), array([2, 2, 2], dtype=int32), array([0, 0, 0], dtype=int32), array([4, 4, 4], dtype=int32), array([5, 5, 5], dtype=int32)]\n",
      "t = [array([4, 2, 0, 4, 5], dtype=int32), array([6, 2, 0, 4, 5], dtype=int32), array([5, 2, 0, 4, 5], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "#-----Test for unstack------#\n",
    "import tensorflow as tf\n",
    "\n",
    "A = [ [4,6, 5 ], \n",
    "      [2,2, 2],\n",
    "     [0,0, 0 ],\n",
    "     [4,4, 4 ],\n",
    "     [5, 5, 5 ]\n",
    "    ]\n",
    "\n",
    "u = tf.unstack(A, axis = 0)\n",
    "t = tf.unstack(A, axis = 1)\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    print('u = ' + str( sess.run(u) ) )\n",
    "    print('t = ' + str( sess.run(t) ) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u = [array([[4, 6, 5],\n",
      "       [2, 2, 2]], dtype=int32), array([[0, 0, 0],\n",
      "       [4, 4, 4]], dtype=int32), array([[5, 5, 5],\n",
      "       [6, 6, 6]], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "#-----Test for unstack------#\n",
    "import tensorflow as tf\n",
    "\n",
    "A = [  \n",
    "      [ \n",
    "            [4,6, 5 ], \n",
    "            [2,2, 2] \n",
    "      ],\n",
    "      [\n",
    "         [0,0, 0 ],\n",
    "         [4,4, 4 ]\n",
    "         \n",
    "      ],\n",
    "      [\n",
    "          [5, 5, 5 ],\n",
    "          [6, 6, 6]\n",
    "      ]\n",
    "    ]\n",
    "\n",
    "u = tf.unstack(A, 3)\n",
    "# t = tf.unstack(A, 3, axis = 1)\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    print('u = ' + str( sess.run(u) ) )\n",
    "#     print('t = ' + str( sess.run(t) ) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ran_norm = [[ 1.07031202 -0.61447394  0.23734196  0.86800736  0.03217022 -0.73966962\n",
      "   0.45953852]\n",
      " [ 0.49735177  0.31650037  1.19679868 -0.10334399 -0.92777944 -1.43667126\n",
      "   0.82876015]\n",
      " [ 0.25597674  0.29477075  1.01669419  0.80626851  1.29378831  0.30296737\n",
      "  -0.08579311]]\n"
     ]
    }
   ],
   "source": [
    "#-----Test for random_normal------#\n",
    "import tensorflow as tf\n",
    "\n",
    "in_size = 3\n",
    "out_size = 7 \n",
    "ran_norm = tf.random_normal([in_size, out_size])\n",
    "                            \n",
    "with tf.Session() as sess:\n",
    "    print('ran_norm = ' + str( sess.run(ran_norm) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy = [[ 0.20753783  0.30961007  0.22936477  0.25348729]\n",
      " [ 0.21875799  0.26719162  0.29529241  0.21875799]]\n",
      "log_probs = [[-1.57243681 -1.17243838 -1.47243738 -1.3724376 ]\n",
      " [-1.51978469 -1.31978536 -1.21978581 -1.51978469]]\n",
      "u=[[-0.         -0.         -1.47243738 -0.        ]\n",
      " [-0.         -0.         -0.         -1.51978469]]\n",
      "u2=[-1.47243738 -1.51978469]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "logits =  [ [0.1,0.5,0.2,0.3],\n",
    "            [0.3,0.5,0.6,0.3] ]\n",
    "# log_probs = [-10, -7, -5, -3]\n",
    "NUM_ACTIONS = 4\n",
    "action = [2,3]\n",
    "\n",
    "policy = tf.nn.softmax(logits, name='policy')\n",
    "log_probs = tf.log(policy + 1e-6)\n",
    "\n",
    "u = log_probs * tf.one_hot(action, NUM_ACTIONS)\n",
    "u2= tf.reduce_sum(u, 1)\n",
    "# u = tf.reduce_sum(log_probs * tf.one_hot(action, NUM_ACTIONS), 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('policy = ' + str( sess.run(policy) ) )\n",
    "    print('log_probs = ' + str( sess.run(log_probs) ) )\n",
    "    print('u=' + str(sess.run(u) ) )\n",
    "    print('u2=' + str(sess.run(u2) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument None has invalid type <type 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-334c425d86a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iclab/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iclab/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m--> 984\u001b[0;31m         self._graph, fetches, feed_dict_string, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iclab/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \"\"\"\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iclab/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iclab/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \"\"\"\n\u001b[1;32m    336\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iclab/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       raise TypeError('Fetch argument %r has invalid type %r' %\n\u001b[0;32m--> 227\u001b[0;31m                       (fetch, type(fetch)))\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument None has invalid type <type 'NoneType'>"
     ]
    }
   ],
   "source": [
    "#wrong\n",
    "import tensorflow as tf\n",
    "\n",
    "w1 = tf.Variable([[1,2]])\n",
    "w2 = tf.Variable([[3,4]])\n",
    "\n",
    "res = tf.matmul(w1, [[2],[1]])\n",
    "\n",
    "grads = tf.gradients(res,[w1,w2])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    re = sess.run(grads)\n",
    "    print(re)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

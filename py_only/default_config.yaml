connect: 
    server_worker_num: &ref_server_worker_num 4
    client_num: 4
    client_retries: 3
    
RL:
    method: 'A3C'
    state_frames: 1
    state_shape: !!python/tuple [7,]
    action_num: 4
    action_bound: [-1,1]
    train_run_steps: 5

A3C:
    LR_A: 0.0001  # learning rate for actor (1e-4)
    LR_C: 0.0002  # learning rate for critic
    GAMMA: 0.9  # reward discount
    ENTROPY_BETA: 0.01
    main_net_scope: 'Main_Net'
    worker_num: *ref_server_worker_num # refer to server_worker_num

log:
    output_tf: yes
    output_tf_dir: './log'
    